{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a12956d",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9606deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage, TextContentItem\n",
    "\n",
    "load_dotenv()\n",
    "MODEL_DEPLOYMENT = os.getenv(\"MODEL_DEPLOYMENT\")\n",
    "PROJECT_ENDPOINT = os.getenv(\"PROJECT_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66dd8f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client = AIProjectClient(\n",
    "    credential=DefaultAzureCredential(\n",
    "        exclude_environment_credential=True,\n",
    "        exclude_managed_identity_credential=True\n",
    "    ),\n",
    "    endpoint=PROJECT_ENDPOINT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e865dbe0",
   "metadata": {},
   "source": [
    "Make sure to check the deployment's connected resource. \n",
    "\n",
    "It may be connected to other project if there is no quota left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad82eb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Phi-4-multimodal-instruct', 'type': 'ModelDeployment', 'modelName': 'Phi-4-multimodal-instruct', 'modelVersion': '1', 'modelPublisher': 'Microsoft', 'capabilities': {'chat_completion': 'true'}, 'sku': {'name': 'GlobalStandard', 'capacity': 1}}\n",
      "{'name': 'text-embedding-ada-002', 'type': 'ModelDeployment', 'modelName': 'text-embedding-ada-002', 'modelVersion': '2', 'modelPublisher': 'OpenAI', 'capabilities': {'embeddings': 'true'}, 'sku': {'name': 'GlobalStandard', 'capacity': 120}}\n"
     ]
    }
   ],
   "source": [
    "for deployment in project_client.deployments.list():\n",
    "    print(deployment.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da332b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_client = project_client.inference.get_chat_completions_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee16ee68",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c654baf1",
   "metadata": {},
   "source": [
    "## Prompt with audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b25ce5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person is updating their order for next month's delivery.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"https://github.com/MicrosoftLearning/mslearn-ai-language/raw/refs/heads/main/Labfiles/09-audio-chat/data/avocados.mp3\"\n",
    "response = chat_client.complete(\n",
    "    model=MODEL_DEPLOYMENT,\n",
    "    messages=[\n",
    "        UserMessage(\n",
    "            [\n",
    "                TextContentItem(text=\"What is the person talking about?\"),\n",
    "                {\n",
    "                    \"type\": \"audio_url\",\n",
    "                    \"audio_url\": {\"url\": file_path}\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77ba6c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The customer, Sarah from Kentosso Cake Shop in Midtown Manhattan, is preparing for the spring festival and wants to order two boxes of strawberries to be delivered this Friday. She is expecting a call to confirm the order.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"https://github.com/MicrosoftLearning/mslearn-ai-language/raw/refs/heads/main/Labfiles/09-audio-chat/data/fresas.mp3\"\n",
    "response = chat_client.complete(\n",
    "    model=MODEL_DEPLOYMENT,\n",
    "    messages=[\n",
    "        UserMessage(\n",
    "            [\n",
    "                TextContentItem(text=\"Can you summarize this customer's voice message?\"),\n",
    "                {\n",
    "                    \"type\": \"audio_url\",\n",
    "                    \"audio_url\": {\"url\": file_path}\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce745fd",
   "metadata": {},
   "source": [
    "## Prompt with image file (using image URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d737e53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image contains a header with the text \"Voice Live\" in bold, followed by a \"Preview\" button. Below the header, there's a description that reads \"Engage in natural conversations with a voice agent with a realistic AI voice and interactive avatar.\" To the left of the text, there is an illustration of a speech bubble with a graph icon on the upper left corner and an audio speaker icon on the upper right corner. The background is white with a light gradient at the bottom.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"https://github.com/MicrosoftLearning/mslearn-ai-language/raw/refs/heads/main/Instructions/media/voice-live-tile.png\"\n",
    "response = chat_client.complete(\n",
    "    model=MODEL_DEPLOYMENT,\n",
    "    messages=[\n",
    "        UserMessage(\n",
    "            [\n",
    "                TextContentItem(text=\"What is the content of the image?\"),\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": file_path}\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35021e8",
   "metadata": {},
   "source": [
    "## Prompt with image file (using Base64 image data)\n",
    "\n",
    "The url value should be in this format `data:{mime_type};base64,{base64_encoded_data}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bce3d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man walking a dog in a city\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "image_file = \"data/street.jpg\"\n",
    "with open(image_file, \"rb\") as f:\n",
    "    b64_image = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "response = chat_client.complete(\n",
    "    model=MODEL_DEPLOYMENT,\n",
    "    messages=[\n",
    "        UserMessage(\n",
    "            [\n",
    "                TextContentItem(text=\"Write a short description for this image?\"),\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{b64_image}\"}\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
